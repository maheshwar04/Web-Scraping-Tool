# ğŸ” Web Scraping Tool (Python + SQLite3)

## ğŸ“Œ Overview  

This script scrapes **paragraphs** (`<p>` tags) from a given website and stores them in an **SQLite database**. It clears old data before inserting fresh content, ensuring efficiency.  

## âš™ï¸ Setup & Installation  

1ï¸âƒ£ Install dependencies: `pip install requests beautifulsoup4`  

2ï¸âƒ£ Run the script: `python scraper.py`  

3ï¸âƒ£ Verify stored data in SQLite: `sqlite3 scraped_data.db` then `SELECT * FROM scraped_content LIMIT 5;`  

## ğŸ“ Features  

âœ” Scrapes **paragraphs** from any website  âœ” Stores data in **SQLite3** database  âœ” **Drops table** before inserting fresh data  âœ” Optimized for **efficiency & error handling**  

## ğŸ” How It Works  

1. Fetches website HTML using `requests` 2. Extracts `<p>` tags using `BeautifulSoup` 3. Drops old table and creates a fresh one 4. Saves new paragraphs into SQLite 5. Prints execution time for efficiency check  

## ğŸ“Œ Example Output (Terminal Preview)  

âœ… Connected to database: scraped_data.db  ğŸ—‘ï¸ Dropped existing table!  âœ… Page loaded successfully!  ğŸ“œ Found 32 paragraphs!  âœ… 28 new paragraphs saved!  â³ Execution Time: 3.21 seconds  ğŸ”’ Database closed.  

## ğŸš€ Customization  

- Change `URL` in `scraper.py` 

## âŒ Issues & Fixes  

| Issue | Fix |  

|-----------------|-------------------|  

| `requests.exceptions.ConnectionError` | Check internet / try different URL |  

| `sqlite3.OperationalError: database is locked` | Close database before re-running |  

| No paragraphs found | Ensure site allows scraping |  

## ğŸ“§ Need Help?  

Feel free to ask for improvements! ğŸš€